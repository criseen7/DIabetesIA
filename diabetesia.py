# -*- coding: utf-8 -*-
"""DiabetesIA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cPKrVIX6NybrWwjszJLbIyTUuChxA3R6

# Mi primera IA
# Es hacer la exploración y análisis de datos (EDA)
  - Observación
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc
from sklearn.preprocessing import StandardScaler
import seaborn as sns

data = pd.read_csv('/content/diabetes.csv')#Crear el dataframe en Pandas desde el Dataset
data

data.head() # Primeros 5 registros

data.tail() # Últimos 5 registros

data.info()

data.describe() # Información estadística de los datos

plt.hist(data['Pregnancies'])
plt.title('Histograma de embarazos')
plt.xlabel('Embarazos')
plt.ylabel('Frecuencia')
plt.show

plt.hist(data['BMI'])
plt.title('Histograma de IMC')
plt.xlabel('IMC')
plt.ylabel('Frecuencia')
plt.show

plt.hist(data['Age'])
plt.title('Histograma de edad')
plt.xlabel('Edad')
plt.ylabel('Frecuencia')
plt.show

#Matriz de correlación
matriz_correlacion = data.corr()
plt.imshow(matriz_correlacion, cmap = 'coolwarm', interpolation = 'nearest')
plt.colorbar()
plt.title('Matriz de correlación')
plt.xticks(range(len(matriz_correlacion.columns)), matriz_correlacion.columns, rotation=45)
plt.yticks(range(len(matriz_correlacion.columns)), matriz_correlacion.columns)
plt.show()

corr_outcome = matriz_correlacion['Outcome'].abs().sort_values(ascending = False)
corr_outcome

"""#Hipotésis"""

#Puliendo el dataframe
data_pulida = data.drop(columns=['SkinThickness','BloodPressure'])
data_pulida

#Preprocesamiento

"""#Experimento
División de datos y Entrenamiento
"""

x = data_pulida.drop(columns=['Outcome']).values
y = data_pulida['Outcome'].values

'''
Dividir los datos
4 segmentos de datos
  x trian
  x test
  y train
  y test

  Para una buena división debemos tener 80%-70% de datos para entrenar y 20%-30% para probar/testear
'''
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)
x_train

"""Vamos a usar Regresión

ML supervisado
-Regresión: Cuando quieres predecir un valor continuo(inf a -inf)
-Clasificación: Cuando quieres predecir valores discretos
"""

#El escalamiento siempre va en x y el atrget no se toca
scaler = StandardScaler()
x_train_escalada = scaler.fit_transform(x_train)
x_test_escalada = scaler.transform(x_test)
x_train_escalada

#Entrenamiento
model = LogisticRegression()
model.fit(x_train, y_train)
intercept = model.intercept_
intercept

coef = model.coef_[0]
coef

"""Análisis y evaluación de resultados"""

y_pred = model.predict(x_test)
y_pred

matriz = confusion_matrix(y_test, y_pred)
plt.figure(figsize = (6,6))
sns.heatmap(matriz, annot=True, fmt='d')
plt.xlabel('Predicción')
plt.ylabel('Valor real')
plt.title('Matriz de confusión')
plt.show()

reporte = classification_report(y_test, y_pred) #F1 score ->1 mejor
print(reporte)#Precisión global del 76%